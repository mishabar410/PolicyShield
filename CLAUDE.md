# PolicyShield — Декларативный firewall для tool calls AI-агентов

## Одной строкой

Ты пишешь правила в YAML → PolicyShield исполняет их на каждом tool call агента → ты получаешь аудитный лог.

---

## Проблема

AI-агенты (nanobot, LangChain, CrewAI, AutoGen) взаимодействуют с реальным миром через **tool calls** — вызовы инструментов: выполнение shell-команд, чтение/запись файлов, HTTP-запросы, отправка сообщений, создание подагентов.

Сегодня контроль над этими действиями осуществляется двумя способами:

1. **Промптами.** "Ты не должен удалять файлы." — LLM может проигнорировать это при достаточно сложном контексте, prompt injection или hallucination.

2. **Точечными хардкодами.** Regex deny-patterns на shell-команды, `restrict_to_workspace` на файловые операции. Каждый фреймворк изобретает свои ad-hoc проверки, которые:
   - не покрывают все tools,
   - не знают про корпоративные политики,
   - не оставляют аудитного следа,
   - не дают агенту шанса исправиться (просто "Error").

**Результат:** компании не могут развернуть AI-агентов в production, потому что не могут гарантировать, что агент не нарушит политики, и не могут доказать compliance аудиторам.

---

## Решение

PolicyShield вводит промежуточный слой между LLM и инструментами — **policy enforcement middleware**, который:

1. **Перехватывает** каждый tool call перед исполнением
2. **Проверяет** его против набора декларативных правил
3. **Принимает решение**: разрешить, заблокировать, отредактировать аргументы, запросить подтверждение у человека
4. **При блокировке** — возвращает агенту структурированное объяснение (counterexample), позволяя перепланировать действие
5. **Записывает** каждое решение в аудитный лог

Правила описываются в **YAML DSL** (не генерируются автоматически из документов, а пишутся человеком) — это сознательное решение, объяснённое ниже.

---

## Три столпа архитектуры

```
┌─────────────────────────────────────────────────────┐
│                   PolicyShield                       │
│                                                      │
│   1. RULES           2. SHIELD          3. TRACE     │
│   ─────────          ──────────         ─────────    │
│   YAML DSL           Runtime            Audit Log    │
│   описывает          enforcement        каждого      │
│   политики           на каждом          решения      │
│   декларативно       tool call          в JSONL      │
└─────────────────────────────────────────────────────┘
```

### Столп 1: Rules (YAML DSL)

Набор файлов в формате YAML, где каждое правило описывает:
- **Когда** применяется (какой tool, какие аргументы, какие условия)
- **Что** делать (заблокировать, разрешить, отредактировать, запросить подтверждение)
- **Почему** (человекочитаемое объяснение для агента и для аудита)

Правила загружаются при старте агента из указанной директории. Поддерживается несколько файлов (по темам: security.yaml, privacy.yaml, compliance.yaml), которые мержатся в единый набор.

Формат правил выбран так, чтобы быть знакомым разработчикам, работавшим с:
- GitHub Actions (`on: ... jobs: ...`)
- Kubernetes NetworkPolicy / OPA Rego
- ESLint / Semgrep rules
- Firewall rulesets (iptables, AWS Security Groups)

Подробная спецификация DSL — в TECHNICAL_SPEC.md, раздел 3.

### Столп 2: Shield (Runtime Enforcement)

Middleware, который встраивается в tool execution pipeline агентного фреймворка. Для каждого tool call:

**Pre-call check:**
- Идентификация tool и его аргументов
- Сопоставление с правилами (pattern matching)
- PII-детекция в аргументах (regex-based, уровень L0)
- Проверка сессионных счётчиков (rate limits)
- Вынесение вердикта: `ALLOW`, `BLOCK`, `APPROVE`, `REDACT`

**Post-call check:**
- Сканирование результата tool call на PII-утечки
- Вердикт: `ALLOW` или `REDACT` (маскировка чувствительных данных в результате)

**Repair Loop (ключевая фича):**

Когда tool call заблокирован, агент получает не просто "Error", а **структурированное объяснение** — counterexample:
- Какое правило сработало
- Что именно нарушено (конкретный аргумент, паттерн)
- Рекомендация по исправлению
- Список разрешённых альтернатив

Это позволяет LLM **перепланировать** действие в рамках того же запроса, без вмешательства человека. Ни один из существующих guardrail-решений (Guardrails AI, NeMo Guardrails, LlamaGuard) не предоставляет repair loop для tool calls — они работают на уровне LLM output, а не на уровне действий.

### Столп 3: Trace (Audit Log)

Каждое решение shield записывается в JSONL-лог:
- Временная метка
- Tool name и хеш аргументов (или полные аргументы, настраивается)
- Сработавшее правило (id, описание)
- Вердикт
- Обнаруженный PII (если есть)
- ID сессии

Trace предоставляет команды CLI для просмотра, фильтрации и агрегации:
- Просмотр сессии
- Статистика за период
- Фильтрация по правилу, вердикту, tool

---

## Почему не Policy Compiler (автогенерация правил из документов)

Первоначальная идея PolicyShield предполагала **автоматический компилятор**, который берёт PDF/Markdown корпоративных политик и превращает их в машиночитаемые правила. Это было сознательно убрано по следующим причинам:

1. **Это NLU-задача research-уровня.** Извлечение формальных правил из неструктурированного юридического текста с точностью, достаточной для enforcement, — нерешённая проблема. Ошибка в компиляции = неправильное правило = либо блокировка легитимных действий, либо пропуск нарушений.

2. **Ложное чувство безопасности.** Если пользователь загрузил PDF и получил "скомпилированные правила", он склонен доверять им без проверки. Ручные YAML-правила заставляют человека осознанно формулировать каждое ограничение.

3. **Размытие фокуса.** Policy Compiler — это отдельный продукт (по сути, LegalTech NLP), который требует своих данных, бенчмарков и итераций. Совмещение с runtime enforcement замедлит обе части.

4. **YAML-правила достаточны для 0→1.** Организация, пишущая 10-50 правил вручную, получает полный контроль и понимание. Если спрос на автогенерацию подтвердится — это станет отдельным компонентом (v2.0+).

---

## Позиционирование среди существующих решений

| Решение | Что делает | Чего не делает |
|---------|------------|----------------|
| **Guardrails AI** | Валидация LLM output (формат, hallucination) | Не работает на уровне tool calls |
| **NeMo Guardrails** | Conversational flow control | Не enforcement, а "рельсы" для диалога |
| **LlamaGuard** | Safety classifier для LLM output | Не declarative rules, не tool-level |
| **OPA / Cedar** | Policy engine (общего назначения) | Не интегрирован с агентными фреймворками, нет repair loop |
| **Nanobot deny_patterns** | Regex-блокировка shell-команд | Покрывает только ExecTool, нет аудита |
| **PolicyShield** | Declarative enforcement на каждом tool call + repair loop + audit trail | Не валидирует LLM output, не NLP compiler |

**Ключевые отличия PolicyShield:**
1. Работает **на уровне tool calls**, а не на уровне LLM output
2. **Repair loop** — агент может исправиться без вмешательства человека
3. **Declarative YAML** — правила читаемы, versionable, reviewable
4. **Audit trail** — доказательство compliance для каждой сессии

---

## Целевой пользователь

1. **Разработчик, использующий nanobot** (или другой агентный фреймворк), который хочет добавить policy enforcement без написания ad-hoc проверок в каждом tool.

2. **Security-инженер / DevSecOps**, которому нужно контролировать, что AI-агенты делают в production среде, и получать аудитный след.

3. **Команда, проходящая compliance-аудит** (SOC2, GDPR, internal policies), которой нужно доказать, что AI-агент действует в рамках политик.

---

## Стратегия дистрибуции

### Фаза 1: Standalone пакет

PolicyShield распространяется как независимый Python-пакет (`pip install policyshield`). Интеграция с nanobot осуществляется через подмену `ToolRegistry` на `ShieldedToolRegistry` (наследование, не monkey-patch).

Не требует изменений в исходном коде nanobot.

### Фаза 2: PR в nanobot (middleware hooks)

Маленький PR в nanobot (~20-30 строк): добавление middleware API в `ToolRegistry` (`add_middleware(fn)`). Это полезно не только для PolicyShield, но и для любого плагина (логирование, rate limiting, мониторинг).

После мержа PolicyShield переключается с subclass на middleware, сохраняя subclass как fallback.

### Фаза 3: Дополнительные интеграции

Адаптеры для LangChain, CrewAI, AutoGen — тот же YAML DSL, тот же shield engine, только другой интеграционный слой.

---

## Объём проекта (оценка)

| Компонент | LOC (оценка) | Описание |
|-----------|-------------|----------|
| Core (rules, matcher, verdict, PII, session) | ~600-800 | Ядро: загрузка YAML, matching, вердикты |
| Nanobot integration | ~200-300 | ShieldedToolRegistry, middleware, конфиг |
| Trace (recorder, CLI) | ~200-300 | JSONL writer, CLI для просмотра |
| CLI (validate, lint) | ~100-150 | Валидация YAML-правил, линтер |
| Tests | ~500-700 | Покрытие основных сценариев |
| **Итого** | **~1500-2200** | Соразмерно nanobot (~3500 LOC) |

---

## Roadmap

| Версия | Что включает |
|--------|-------------|
| **v0.1** | YAML DSL + Matcher + BLOCK/ALLOW вердикты + L0 PII (regex) + Counterexample (repair loop) + JSONL trace |
| **v0.2** | APPROVE вердикт + Approval flow через каналы nanobot + REDACT вердикт + Batch approve (session cache) |
| **v0.3** | Trace CLI (show / stats / violations) + Rule linter + Rate limiting rules |
| **v0.4** | Адаптеры для LangChain / CrewAI + Абстрактный ShieldAdapter интерфейс |
| **v1.0** | Stable API + Полная документация + PyPI publish |

---

## Проектные документы

| Документ | Содержание |
|----------|-----------|
| `CLAUDE.md` (этот файл) | Видение проекта, позиционирование, стратегия |
| `TECHNICAL_SPEC.md` | Детальная техническая спецификация: YAML DSL, matcher engine, вердикты, PII, trace, repair loop |
| `INTEGRATION_SPEC.md` | Спецификация интеграции с nanobot: архитектура, ShieldedToolRegistry, конфигурация, approval flow |
